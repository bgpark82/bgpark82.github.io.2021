---
layout: single
title: OS
---

# 1. 운영체제와 컴퓨터
운영체제(OS, Operating System)은 **사용자가 컴퓨터를 쉽게 다르게 해주는 인터페이스**이다.

**운영체제의 역할**

1. CPU 스케쥴링과 프로세스 관리 : 프로세스의 생성, 삭제, 자원 할당 및 프로세스의 CPU 소유권을 할당한다
2. 메모리 관리 : 한정된 메모리를 어떤 프로세스에 할당할지 관리한다
3. 디스크 파일 관리 : 디스크 파일을 어떻게 보관할지 관리한다
4. IO 디바이스 관리 : IO 디바이스들과 컴퓨터간에 데이터를 주고 받는 것을 관리한다

**운영체제의 구조**

- 유저 프로그램
- **GUI**
- **시스템콜** : 운영체제가 커널에 접근하기 위한 인터페이스
- **커널** : 시스템 콜 인터페이스를 제공하여 메모리, 프로세스, 파일 시스템, IO 디바이스 등 중추적인 역할을 한다.
- **드라이버** : 하드웨어를 사용하기 위한 소프트웨어 
- 하드웨어

GUI는 있을 수도 있고 없을 수도 있으니 결국 OS는 시스템 콜, 커널, 드라이버로 구성된다. 

시스템콜은 **운영체제가 커널에 접근하지 위한 인터페이스**이다. 어플리케이션이 운영체제의 리소스를 사용하기 위해 커널 함수를 호출할 때 사용된다. 예를들어, 사용자가 자바 어플리케이션을 통해 파일을 읽는 요청을 하면 자바가 파일 읽기 요청을 보내는 메소드를 작성하면 내부적으로 시스템 콜을 통해 파일을 읽는 하는 커널 함수를 호출하게 된다. 

![image-20220519013533495](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519013533495.png)

이때 유저 모드에서 커널 모드로 들어가 파일을 읽고 다시 유저모드로 돌아가 로직을 수행한다. 유저모드와 커널모드로 나눠진 이유는 유저모드에서 공격자가 악의적인 행동이 하드웨어 동작으로 이어지지 못하게 막는 역할을 한다.

> 어플리케이션 -> 유저모드 -> 시스템 콜 -> 커널모드 -> IO -> 유저모드 -> 어플리케이션

![image-20220519013925709](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519013925709.png)

시스템 콜은 메모리 영역과 하드웨어 영역을 추상화하는 인터페이스이다.

> modebit
>
> 시스템 콜은 modebit으로 유저 모드와 커널 모드를 구분한다
>
> 유저 모드를 1, 커널 모드는 0으로 설정되며 1일 경우 시스템 콜을 하지 못하게 막는다

## 1.2. 컴퓨터의 요소

컴퓨터는 CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져있다.

![image-20220519014822865](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519014822865.png)

### 1.2.1. CPU

CPU (Central Processing Unit)는 산술논리연산장치, 제어장치, 레지스터로 구성되어 있다. 인터럽트에 의해 **메모리의 명령어를 해석하여 실행**한다.

아래 그림에서 **운영체제의 커널이 프로그램을 메모리에 올려 프로세스로 만들면 CPU가 이를 처리**한다

![image-20220519015025316](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519015025316.png)

**제어장치**

제어장치 (CU, Control Unit)는 CPU의 부품으로 **명령어들을 읽고 해석하며 입출력 장치간 통신을 제어**한다.

**레지스터**

레지스터 (Register)는 **CPU 안의 매우 빠른 임시기억장치**를 말한다. CPU와 직접 연결되어 있어 연산 속도가 메모리보다 매우 빠르다. CPU는 자체적으로 데이터를 저장하지 못하므로 레지스터를 거쳐 메모리에 데이터를 전달한다

**산술논리연산 장치**

산술논리연산장치 (ALU, Arithmetic Logic Unit)은 덧셈, 뺄셈과 같은 **산술 연산**과 배타적 논리합, 논리곱 같은 **논리연산**을 계산한다

![image-20220519015911190](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519015911190.png)

CPU의 연산처리는 다음과 같다.

1. 제어 장치가 메모리와 레지스터에 계산할 값을 로드한다
2. 제어 장치가 산술논리연산장치(ALU)에게 레지스터의 값을 계산하라 명령한다
3. 제어 장치가 계산된 결과를 레지스터를 통해 메모리로 저장하라 명령한다

**인터럽트**

인터럽트는 **신호가 들어왔을 때, CPU를 잠시 정지**시키는 것이다. 

주로 키보드, 마우스 등 IO 디바이스로 인한 인터럽트, 0으로 나눴을 때 산술 연산에서 인터럽트, 프로세스 오류 등으로 발생한다.

인터럽트의 종류는 하드웨어 인터럽트와 소프트웨어 인터럽트가 있다. 

- 하드웨어 인터럽트 : 키보드, 마우스 연결 등 IO 디바이스에서 발생하는 인터럽트. 운영체제에 시스템 콜을 요청해서 원하는 디바이스로 향해 디바이스의 작은 로컬 버퍼에 접근한다
- 소프트웨어 인터럽트 : 프로세스 오류 등으로 프로세스가 시스템 콜을 호출할 때 발동한다.



### 1.2.2. DMA 컨트롤러

DMA 컨트롤러는 **IO 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치**이다

CPU에 많은 인터럽트 요청이 들어오므로 CPU를 부하를 줄여주는 역할을 한다



### 1.2.3. 메모리

메모리는 **전자 회로에서 데이터, 상태, 명령어 등을 기록하는 공간**이다. 

CPU는 계산을 담당하는 공간이고, 메모리는 기억을 담당하는 공간이다

CPU는 일꾼이며, 메모리는 작업장이며, 메모리의 크기가 작업장의 크기이다. 



### 1.2.4. 타이머

타이머는 **몇 초 안에는 작업이 끝나야 하는지 제한 시간을 걸어둔다.** 



### 1.2.5. 디바이스 컨트롤러 

디바이스 컨트롤러는 컴퓨터와 연결된 IO 디바이스들의 작은 CPU를 말한다



# 3. 메모리

### 3.1 메모리 계층

메모리 계층은 레지스터, 캐시, 메모리, 저장 장치로 구성되어 있다

![image-20220519225229709](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519225229709.png)

- 레지스터 : CPU 안의 작은 메모리, 가장 빠르고 용량이 가장 적다
- 캐시 : L1, L2, L3 캐시 가르키며 속도빠르고 용량이 적다
- 메모리 : 속도, 용량이 보통이다. 하드디스크로 데이터를 복사해 임시 저장하고, 필요할 때마다 CPU의 레지스터로 전달한다
- 하드디스크 : 속도가 낮고 용량이 많다

### 1.3.1 캐시

캐시는 임시 저장소이며 **빠른 장치와 느린 장치의 속도차에 의한 병목 현상을 줄여준다**.

데이터 접근 시간을 줄이며 다시 계산하는 시간을 절약할 수 있다. 실제 메모리와 CPU의 속도차가 너무 커 중간에 레지스터를 둬서 속도차이를 해결한다. 

***지역성의 원리***

캐시를 직접 설정할 때 **자주 사용하는 데이터를 기반**으로 캐시를 설정한다

자주 사용하는 데이터의 근거는 **지역성**이다

1. 시간 지역성 : **최근 사용한 데이터에 다시 접근하려는 특성**을 말한다. for 문에서 i=0
2. 공간 지역성 : **최근 접근한 데이터의 공간에 접근하려는 특성**을 말한다. for 문에서 i=0

***캐시 히트 vs 캐시 미스 vs 캐시 매핑*** 

![image-20220519230958655](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519230958655.png)

캐시 히트는 **캐시에서 원하는 데이터를 찾은 것**을 말한다. CPU 내부 버스로 동작하므로 매우 빠르다

캐시 미스는 **캐시에서 원하는 데이터가 없다면 메모리로 가서 데이터를 캐시로 찾아오는 것**을 말한다. 시스템 버스로 메모리에서 데이터를 가져와 느리다

캐시 매핑은 **캐시가 히트되기 위해 매핑하는 방법**을 말한다.

| 이름           | 설명                                                         |
| -------------- | ------------------------------------------------------------ |
| 직접 매핑      | 메모리 100, 캐시 10이 있다면 1:10 등의 비율로 매핑. 빠르지만 충돌 발생이 많다 |
| 연관 매핑      | 순서없이 연관된 메모리와 캐시를 매핑. 충돌이 적지만 모든 블록을 탐색해서 느리다 |
| 직접 연관 매핑 | 직접 매핑 + 연관 매핑. 순서는 일치하지만 집합을 둬서 블록화 되므로 검색은 효율적입니다. |



***웹 브라우저의 캐시***

- 쿠키 : 쿠키는 **만료기한이 있는 키-값 저장소**이다. same-site 옵션을 strict으로 설정하지 않으면 다른 도메인 요청에 자동 전송되며, 4KB까지 데이터를 저장할 수 있고 주로 서버에서 만료 기한을 설정가능하다. httponly 옵션으로 doucment.cookie로 볼 수 없게 하는 것이 중요하다

- 로컬 스토리지 : 로컬 스토리지는 **만료기한이 없는 키-값 저장소**이다. 10MB까지 저장가능하며 웹 브라우저를 닫아도 유지되고 도메인 단위로 저장, 생성된다. HTML5만 지원하며 클라이언트에서만 수정 가능하다

- 세션 스토리지 : 세션 스토리지는 **만료기한 없는 키-값 저장소**이다. 탭 단위로 세션 스토리지를 생성하며, 탭을 닫으면 해당 데이터가 삭제된다. 5MB까지 저장가능하며 HTML5만 지원하며 클라이언트에서만 수정가능하다 

**데이터베이스의 캐시**

![image-20220519235415718](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220519235415718.png)

### 1.3.2 메모리 관리

OS는 한정된 메모리 최대한 사용하도록 관리한다

***가상 메모리*** 

가상 메모리는 **컴퓨터의 실제 메모리를 추상화하여 사용자에게 큰 메모리로 보이게 만드는 것**을 말한다

가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 페이지 테이블로 관리되며 속도 향상을 위해 TLB를 사용한다

페이지 테이블을 **프로세스의 주소 정보**를 가지고 있다.

TLB는 **메모리와 CPU 사이에 주소 변환을 위한 캐시**이다. 페이지 테이블에 있는 리스트를 보관하여 CPU가 페이지 테이블까지 가지 않도록 하여 속도를 향상 시킬 수 있는 캐시 계층이다.

가상 주소는 가상적으로 주어진 주소를 말하며 실제 주소는 메모리의 주소를 말한다

***스와핑***

**가상 메모리에는 존재하지만 실제 메모리에 없는 데이터에 접근**할 경우 페이지 폴트가 발생한다

이를 방지하기 위해 사**용하지 않는 영역을 하드 디스크로 옮겨 필요할 때 실제 메모리로 불러와 올리고**, 사용하지 않으면 하드 디스크로 내려서 메모리를 효과적으로 관리하는 것이 스와핑이라 한다.

***페이지 폴트***

프로세스의 주소 공간에는 존재하지만 실제 메모리에 존재하지 않는 데이터에 접근하는 경우 발생한다.

1. CPU는 물리 메모리를 확인한다
2. 해당 페이지가 없으면 트랩을 발생해서 OS에 알린다
3. OS는 CPU의 동작을 잠시 멈춘다
4. OS는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인한다
5. 없으면 프로세스를 중단하고 물리 메모리에 비어있는 프레임이 있는지 찾는다
6. 물리 메모리에도 없으면 스와핑으로 하드 디스크에서 데이터를 가져온다
7. 비어 있는 프레임에 해당 페이지를 로드한다.
8. 페이지 테이블을 최신화 한다
9. 중단된 CPU를 다시 시작한다.

***페이지***

페이지는 가상 메모리를 사용하는 최소 크기 단위이다

***프레임***

실제 메모리를 사용하는 최소 크기 단위이다.

### 1.3.3 스레싱

스레싱(thrashing)은 메모리의 페이지 폴트율이 높은 것을 의미한다. 성능 저하를 초래한다

스레싱은 메모리에 너무 많은 프로세스가 동시에 올라와 스와핑이 많이 발생하여 생기는 현상이다

페이지 폴트가 일어나면 CPU를 중단시키는 시간이 많아 CPU이용률이 낮아지고 OS는 CPU가 여유로운지 알고 더 많은 프로세스를 올리게 된다

해결법은 메모리를 늘리거나 SDD로 바꾼다. OS에서는 작업 세트와 PFF가 있다

***작업 세트***

작업 세트는 프로세스의 사용 이력을 통해 페이지 집합을 만들어 미리 메모리에 로드하는 것이다. 미리 메모리에 로드하면 탐색 비용을 줄이고 스와핑을 줄인다

***PFF***

PFF (Page Fault Frequency)는 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법이다.

상한선에 도달하면 페이지를 늘리고 하한선에 도달하면 페이지를 줄인다



### 1.3.4 메모리 할당

메모리에 프로그램을 할당할 때 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당한다

1. 연속할당 : 연속할당은 메모리에 연속적으로 공간을 할당하는 것을 말한다
   - 고정 분할 방식 : 메모리를 미리 나누어 관리하는 방식, 미리 나눠져 있어서 내부 단편화가 발생한다
   - 가변 분할 방식 : 매 시점에 프로그램의 크기에 맞게 동적으로 메모리를 나눈다. 외부 단편화가 발생한다
2. 불연속 할당 : 메모리를 연속적으로 할당하지 않는다. 현재 운영체제가 쓰며 페이징, 세그멘테이션 페이지드 세그멘테이션이 있다
   - 페이징 기법 : 메모리를 동일한 크기의 페이지 (4KB)로 나누고 프로그램마다 페이지 테이블을 두어 메모리에 프로그램을 할당. 홀의 크기가 균일하지만 주소 변환이 복잡하다
   - 세그멘테이션 : 페이지가 아닌 의미단위의 세그먼트로 나눈다. 프로세스는 코드, 데이터, 스택, 힙으로 구성되며 이를 기반으로 나눈다. 공유와 보안 측면에서 고 홀 크기가 균일하지 않다

>  ***내부 단편화***
>
> 메모리를 나눈 크기보다 프로그램이 작아서 비어있는 공간이 많은 상태. 예를들어 100MB를 50MB, 50MB로 나눴지만 프로그램이 10MB여서 남은 공간이 많을 때
>
> ***외부 단편화***
>
> 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많은 상태. 예를들어 100MB를 50MB, 50MB로 나눴지만 프로그램이 70MB여서 공간을 확보 못할 때

### 1.3.5 페이지 교체 알고리즘

메모리는 한정되어 있기 때문에 스와핑이 많이 일어나며 **페이지 교체 알고리즘 기반으로 스와핑**한다

1. 오프라인 알고리즘 : 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘. 불가능하다
2. FIFO (First In First Out) : 먼저온 페이지를 교체 영역에 놓는 방법을 말한다
3. LRU (Least Recentle Used) : 참조가 가장 오래된 페이지를 바꾼다. 페이지마다 계수기, 스택을 두어 오래된 것을 파악해야 한다 .  보통 해시 테이블과 이중 연결 리스트를 사용한다. 해시 테이블은 이중 연결 리스트를 찾고 이중 연결 리스트는 한정된 메모리를 나타낸다 (자바의 HashMap과 비슷하네)
4. NUR (Not Used Recently) : 0과 1을 가진 비트를 두고. 1은 최근에 참조 0은 참조되지 않음을 의미한다. 시계 방향을 돌면서 0을 찾고 0을 찾은 순간 프로세스를 교체한다. 해당 부분을 1로 바꾼다
5. LFU (Least Frequently Used) : 가장 참조 횟수가 적은 페이지를 교체한다. 즉, 많이 사용되지 않은 것을 교체한다

https://www.youtube.com/watch?v=5pEDL6c--_k&ab_channel=%EC%9A%B0%EC%95%84%ED%95%9CTech

# 4. 프로세스 vs 메모리

프로세스는 컴퓨터에서 실행되는 프로그램을 말한다. 

하드 디스크의 프로그램은 메모리에 올라가면서 프로세스가 되고 CPU의 스케줄러에 따라 CPU가 프로세스를 실행시킨다

스레드는 프로세스 내 작업의 흐름을 말한다 



## 4.1 프로세스의 컴파일 과정

프로세스는 프로그램으로 부터 인스턴스화 된 것을 말한다. 

프로그램은 chrome.exe와 같은 디스크에 있는 실행 파일이며 컴파일러가 컴파일하여 기계어로 번역된 실행될 수 있는 파일을 말한다

![image-20220520220221683](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220520220221683.png)

1. 소스 코드 파일 : 하드 디스크에 있는 소스 코드 파일이다.
2. 전처리 : 소스 코드의 주서을 제거하고 #include 등 헤더 파일을 병합한다
3. 컴파일러 : 오류 처리 코드 최적화 작업을 통해 어셈블리어로 변환한다
4. 어셈블러 : 어셈블리어를 목적 코드(object code)로 변환한다. 확장자는 OS마다 다르다
5. 링커 : 프로그램 내 라이브러리 및 다른 파일과 목적 코드를 결합해 실행 파일을 생성한다. 확장자는 `.exe` 혹은 `.out`이다
   - 정적 라이브러리 : 프로그램 빌드 시 라이브러리가 제공하는 모든 코드를 실행 파일에 넣는 방식. 외부 의존도가 낮고 중복 등 메모리 효율성이 떨어진다
   - 동적 라이브러리 : 프로그램 실행 시 필요한 DLL이라는 함수 정보를 통해 참조하는 방식이다. 메모리 효율성이 높지만 외부 의존도가 높다

## 4.2 프로세스 상태

![image-20220520220538086](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220520220538086.png)

프로세스는 여러 상태값을 가진다

1. 생성상태 : `fork()`, `exec()` 함수로 프로세스를 생성한다. 이때 PCB에 할당된다
   - `fork()`는 부모 프로세스의 주소를 그대로 복사해서 새로운 자식 프로세스를 생성한다
   - `exec()`는  새로운 프로세스를 생성하는 함수이다.
2. 대기상태 : 메모리 공간이 충분하면 메모리를 할당받고 아니면 대기하고 있는다. CPU CPU 스케줄로 부터 CPU 소유권이 넘어오기를 기다린다
3. 대기 중단 상태 : 메모리 부족으로 일시 중단된 상황
4. 실행 상태 : CPU 소유권과 메모리를 할당 받고 instruction을 수행 중인 상태를 말한다
5. 중단 상태 : 이벤트가 발생한 이후 프로세스가 차단된 상태. IO 디바이스에 의한 인터럽트로 많이 발생한다.
6. 일시 중단 상태 :  중단된 상태에서 프로세스가 실행하려 했지만 메모리 부족으로 일시 중단된 상태이다
7. 종료 상태 : 메모리와 CPU 소유권을 모두 놓고 가는 상태이다. 자연스러운 종료 혹은 부모 프로세스가 자식 프로세스를 종료시키는 경우도 있다. 



## 4.3 프로세스의 메모리 구조

![image-20220520231440842](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220520231440842.png)

1. 스택 : 지역변수, 매개변수, 함수가 저장되고 **컴파일 시에 크기가 결정**되며 동적이다. 힙과 스택의 메모리가 겹치면 안되기 때문에 힙과 스택사이에 공간을 비워놓는다
2. 힙 : 동적 할당할 때 사용되며 **런타임 시 크기가 결정**된다. 
3. 데이터 영역 : **전역변수**( = 정적변수가) 저장, 
   - BSS 영역 : 초기화되지 안은 변수가 0으로 초기화되어 저장
   - Data 영역 : 값으로 할당된 변수들이 저장
4. 코드 영역 : 프로그램에 적힌 소스 코드가 들어가는 영역이다. 

## 4.4 PCB

PCB(Process Control Block)은 OS에서 **프로세스의 메타데이터를 저장**한 것을 말한다

프로그램이 실행되면 프로세스가 생성되고 프로세스 주소값들에 스택, 힙 등이 메모리에 할당된다. 그리고 프로세스의 메타데이터들이 PCB에 저장되어 관리된다

### 4.4.1 PCB의 구조

- 프로세스 스케줄링 상태
- 프로세스 ID
- 프로세스 권한
- 프로그램 카운터
- CPU 레지스터
- CPU 스케줄링 정보
- 계정 정보
- IO 상태 정보

### 4.4.2 컨텍스트 스위칭

컨텍스트 스위칭은 **PCB를 교환하는 과정**을 말하며 프로세스의 할당 시간이 끝나거나 인터럽트에 의해 발생한다.

CPU에서 많은 프로세스들이 동작하고 있지만 어느 한 순간에는 하나의 프로세스가 동작한다. 동시에 동작하고 있는 것처럼 보이는 이유는 프로세스와 컨텍스트 스위칭이 즉, **PCB를 교환하는 시간이 매우 빠르기** 때문이다.

컨텍스트 스위칭이 일어나면 유휴 시간(idle time)이 발생한다. 또한 캐시 미스라는 추가 비용이 든다. 스레드는 스택영역만 차지하므로 스레드의 컨텍스트 비용이 훨씬 적다

캐시 미스는 컨텍스트 스위칭 과정에서 **프로세스의 메모리 주소가 그대로 있으면 안되므로 캐시의 해당 데이터를 지운다**. 그러므로 캐시 미스가 발생한다. 

![image-20220521145002848](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220521145002848.png)

## 4.5 멀티 프로세싱

멀티 프로세싱은 **여러개의 프로세스로 동시에 여러가지 일을 처리**하는 것을 말한다. 

잠정은 하나의 프로세스에 문제가 생겨도 다른 프로세스로 처리할 수 있다.

### 4.5.1 IPC

IPC (Inter Process Communication)은 **프로세스 간 공유 데이터를 관리하는 방법**을 말한다

클라이언트와 서버도 일종의 IPC이다. IPC는 힙, 데이터, 코드가 공유되는 스레드보다 속도가 떨어진다

**종류**

1. 공유 메모리 : 여러 프로세스에 **동일한 메모리 블록에 대한 접근 권한을 부여하여 통신하도록 공유 버퍼**를 사용한다. 매개체를 사용해서 공유 메모리에 접근하는 것이 아니므로 빠르고 오버헤드가 적다. 하지만 동기화가 필요하다. 하드웨어 관점에서 공유 메모리는 CPU에 접근할 수 있는 RAM이 된다.
2. 파일 : **하드 디스크의 파일을 통해 통신**을 한다
3. 소켓 : **동일 컴퓨터의 프로세스 혹은 다른 컴퓨터의 프로세스와 네트워크 인터펭시를 통해 데이터를 통신**한다
4. 익명 파이프 : **프로세스 간 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 통신**한다. 단방향의 읽기, 쓰기 전용 파이프를 사용한다. 부모 자식간만 사용가능하며 네트워크상에서 이용은 불가능하다
5. 명명 파이프 : **파이프 서버와 여러개의 클라이언트간 통신을 위해 단방향 또는 양방향 파이프**를 말한다
6. 메세지 큐 : **데이터를 큐 구조에 담아 통신하는 방식**을 말한다



## 4.6 스레드와 멀티 스레딩

![image-20220521154925833](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220521154925833.png)

### 4.6.1. 스레드

스레드는 프로세스의 실행 가능한 가장 작은 단위이다. 프로세스의 힙, 데이터, 코드 영역을 스레드끼리 공유한다. 

### 4.6.2 멀티 스레드

멀티 스레딩은 프로세스의 작업을 여러개의 스레드로 처리하는 기법이다. 

스레드끼리는 힙, 데이터, 코드 영역을 공유하므로 효율이 높다. 웹 요청처리 시, 프로세스를 생성하는 대신 스레드를 사용하여 더 적은 리소스를 소비한다. 하나의 스레드가 중단(blocked)되어도 다른 스레드는 실행(running) 상태일 수 있으므로 빠른 처리가 가능하다. 또한 공유 자원에 쉽게 접근할 수 있으므로 동시성 이슈가 발생한다



## 4.7 공유자원과 임계영역

### 4.7.1 공유자원

공유 자원은 **프로세스, 스레드가 접근 할 수 있는 모니터, 메모리, 파일 등의 자원**을 말한다.

경쟁 상태(Race Condition)은 2개 이상의 프로세스나 스레드가 공유 자원을 동시에 읽거나 쓰는 상황을 말한다. 

### 4.7.2 임계영역

임계영역(Critical Area)은 **공유 자원이 동시성 이슈로 결과가 달라지는 영역**을 말한다. 

![image-20220521161719571](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220521161719571.png)

임계영역을 해결하는 방법은 3가지가 있다. 공통점은 **잠금(Lock) 메커니즘**을 사용한다. 

1. 뮤텍스 : **하나의 스레드가 공유 자원 사용 전 설정하고, 사용 후 해제**하는 잠금. 잠금이 되면 다른 스레드는 접근할 수 없다. 
2. 세마포어 : **여러개의 스레드가 정수값과 두가지 함수 (`wait`, `signal`)로 공유자원에 대한 접근**을 처리한다. `wait`은 자기 차례가 올때까지 기다리는 함수, `signal`은 다음 프로세스로 순서를 넘겨주는 함수이다
   - 바이너리 세마포어 : 0과 1만 가지는 새마포어, **뮤텍스는 일종의 바이너리 세마포어**이다. 뮤텍스는 리소스에 대한 접근을 동기화하는 잠금 메커니즘이고 세마포어는 신호를 기반으로 한 상호배제가 일어나는 신호 메커니즘이다.
   - 카운팅 세마포어 : 여러개의 값을 가지는 세마포어, 여러 자원에 대한 접근을 제어하는데 사용된다. 
3. 모니터 : **모니터는 둘 이상의 스레드가 공유 자원에 접근하도록 공유자원을 숨기고 해당 접근에 대해 인터페이스만 제공**한다. 모니터큐를 통해 작업들을 순차적으로 처리한다. 모니터는 세마포어보다 구현하기 쉬우며 모니터에서 상호배제는 자동이지만 세마포어는 상호배제를 명시적으로 구현해야 한다.

위 3방법은 모두  상호배제, 한정 대기, 융통성이라는 조건을 만족한다.

1. 상호배제 : **한 프로세스가 한 영역에 들어가면 다른 프로세스는 들어갈 수 없다**. 기본적으로 Lock을 주고 받는 식으로 입장을 통제한다
2. 한정대기 : **한 프로세스가 영원히 임계 영역에 들어가지 못하도록 막으면 안된다**. 임계영역으로 대기를 영원히 하면 안되고 한정된 기간만 하도록 한다.
3. 융통성 : **한 프로세스가 다른 프로세스를 방해하면 안된다.**

> 뮤텍스와 상호배제의 차이점은?

### 4.7.3 교착상태

교착상태 (Deadlock)은 **여러개의 스레드가 자원을 가진 상태로 서로의 자원을 가지려고 무한 기다리는 상태**를 말한다

**원인**

1. 상호배제 : 한 스레드가 자원은 가지고 있으며 다른 스레드는 접근할 수 없다. 즉, 자원을 가진 상태로 다른 스레드가 해당 자원을 획득하기 위해 무한정 기다리는 상황
2. 점유대기 : 한 스레드가 점유한 자원을 다른 스레드가 요청하는 상황이다.
3. 비선점 : 다른 스레드의 자원을 강제로 가져올 수 없다.
4. 환형대기 : 스레드A가 스레드B의 자원을 요구하고 스레드B가 스레드A의 자원을 요구하는 상황이다. 즉, 서로가 서로의 자원을 요구하는 상황

**해결법**

1. 미리 교착상태가 발생하지 않도록 설계한다
2. 교착 상태 가능성이 없을 때만 자원을 할당한다. 은행원 알고리즘을 사용한다
3. 교착 상태 발생 시, 교착 상태가 발생한 스레드를 지운다
4. 교착 상태는 매우 드물기 때문에 사용자가 작업을 그냥 종료한다

> 은행원 알고리즘
>
> 총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 또는 불안정 상태로 나누고 안정 상태로 만들도록 자원을 할당하는 알고리즘이다

## 4.8 CPU 스케줄링 알고리즘

CPU 스케줄러는 **어떤 프로세스에 CPU 소유권을 줄지 결정**한다

CPU 스케줄링 알고리즘으로 **CPU를 주어진 시간동안 많은 일을 하고 각 프로세스들의 응답시간을 짧게 만드는 것을 목표**로 한다

![image-20220521170109939](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220521170109939.png)

### 4.8.1 비선점형 방식

비선점형 방식은 **프로세스가 스스로 CPU 소유권을 포기하는 방식**이다. 강제로 프로세스를 중지하지 않으며 컨텍스트 스위칭에 의한 부담이 적다 

1. FCFS (First Come First Serve) : **가장 먼저 온 프로세스를 먼저 CPU에 할당**하는 알고리즘. 프로세스가 길게 수행된다면 다른 프로세스들이 기다려야하는 단점을 가진다 (convoy effect)
2. SJF (Shortest Job First) : **실행 시간이 가장 짧은 프로세스를 먼저 CPU에 할당**하는 알고리즘. FCFS의 단점을 보완한 알고리즘. 긴 시간을 가진 프로세스는 실행되지 않고 (starvation) 평균 대기시간이 가장 짧다. 하지만 프로세스의 실제 실행 시간은 모르므로 과거 실행시간을 참고한다
3. 우선순위 : **오래된 프로세스일 수록 우선순위를 높혀 CPU에 할당**하는 알고리즘. SJF의 단점을 보완한 알고리즘. 

### 4.8.2 선점형 방식

선점형 방식은 **사용중인 프로세스를 중단하고 강제로 다른 프로세스를 CPU에 할당**한다. 선점형 방식은 현대 운영체제가 사용하는 방식이다

1. 라운드 로빈 : **프로세스에 동일한 CPU 할당 시간을 주고 그 시간안에 끝나지 않으면 다시 Ready Queue로 가는 알고리즘**. 현재 컴퓨터가 사용하는 알고리즘. 할당 시간이 너무 크면 FCFS의 문제가 발생하고, 짧으면 컨텍스트 스위칭이 잦아져 오버헤드가 발생한다. 전체 작업 시간은 길어지지만 평균 응답시간은 짧아진다.
2. SRF (Shortest Remaining First) : ***중간에* 더 짧은 작업이 들어오면 프로세스를 중지하고 해당 프로세스를 실행하는 알고리즘**.
3. 다단계 큐 : **우선순위에 따른 Ready Queue를 여러개 사용하고, Ready Queue마다 라운드 로빈이나 FCFS 등 다른 CPU 스케쥴링 알고리즘을 적용한 알고리즘**. 큐 간 프로세스 이동이 안되므로 스케줄링 부담이 적지만 유연성이 떨어진다.

![image-20220521172011583](https://raw.githubusercontent.com/bgpark82/image/master/images/image-20220521172011583.png)

> CPU 스케줄링 : 프로세스가 CPU에 할당하는 알고리즘
>
> - 비선점형 : FCFS, SJF, 우선순위
> - 선점형 : 라운드로빈, SRF, 다단계 큐
